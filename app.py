import openai
import sys
import os
import json
import traceback
import re
import uuid
import requests
import time
from datetime import datetime
from flask import Flask, request, abort, render_template, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, ImageSendMessage
from firebase_admin import firestore, storage
import firebase_admin
from firebase_admin import credentials, firestore
import base64
import random
from google.cloud import storage

sys.stdout.reconfigure(encoding='utf-8')
app = Flask(__name__)
print("âœ… Flask App initialized")

LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
FIREBASE_CREDENTIALS = os.environ.get("FIREBASE_CREDENTIALS")
LEONARDO_API_KEY = os.environ.get("LEONARDO_API_KEY")  # æ–°å¢ Leonardo API Key

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)
openai.api_key = OPENAI_API_KEY

def get_firebase_credentials_from_env():
    return credentials.Certificate(json.loads(FIREBASE_CREDENTIALS))

firebase_admin.initialize_app(get_firebase_credentials_from_env())
db = firestore.client()

# åˆå§‹åŒ– GCS client
bucket_name = "storybotimage"
gcs_client = storage.Client()
bucket = gcs_client.bucket(bucket_name)

user_sessions = {}
user_message_counts = {}
story_summaries = {}
story_titles = {}
story_image_prompts = {}
story_image_urls = {}
story_current_paragraph = {}
story_paragraphs = {}
illustration_mode = {}
practice_mode = {}

# é€™æ˜¯è¢«éºæ¼çš„è®Šæ•¸å®šç¾©ï¼Œç¾åœ¨å·²ç¶“è£œä¸Š
base_system_prompt = """
ä½ æ˜¯ã€Œå°ç¹ªã€ï¼Œä¸€ä½è¦ªåˆ‡ã€æº«æŸ”ã€æ“…é•·èªªæ•…äº‹çš„ AI å¤¥ä¼´ï¼Œå”åŠ©ä¸€ä½ 50 æ­²ä»¥ä¸Šçš„é•·è¼©å‰µä½œ 5 æ®µæ•…äº‹ç¹ªæœ¬ã€‚
è«‹ç”¨ç°¡æ½”ã€å¥½è®€çš„èªæ°£å›æ‡‰ï¼Œæ¯å‰‡è¨Šæ¯ç›¡é‡ä¸è¶…é 35 å­—ä¸¦é©ç•¶åˆ†æ®µã€‚

ç¬¬ä¸€éšæ®µï¼šæ•…äº‹å‰µä½œå¼•å°ï¼Œè«‹ä»¥ã€Œå¦‚æœæˆ‘æœ‰ä¸€å€‹è¶…èƒ½åŠ›ã€ç‚ºä¸»é¡Œï¼Œå¼•å°ä½¿ç”¨è€…æƒ³åƒä¸€ä½ä¸»è§’ã€ä»–æ“æœ‰ä»€éº¼è¶…èƒ½åŠ›ã€ä»–åœ¨å“ªè£¡ã€é‡åˆ°ä»€éº¼äº‹ä»¶ã€è§£æ±ºäº†ä»€éº¼å•é¡Œï¼Œé€æ­¥ç™¼å±•æˆäº”æ®µæ•…äº‹ã€‚
ä¸è¦ä¸»å°æ•…äº‹ï¼Œä¿æŒå¼•å°èˆ‡é™ªä¼´ã€‚

ç¬¬äºŒéšæ®µï¼šç¹ªåœ–å¼•å°ï¼Œå¹«åŠ©ä½¿ç”¨è€…æè¿°ç•«é¢ï¼Œç”Ÿæˆçš„ç¹ªåœ–ä¸Šä¸è¦æœ‰æ•…äº‹çš„æ–‡å­—ï¼Œä¸¦åœ¨å®Œæˆå¾Œè©¢å•æ˜¯å¦éœ€èª¿æ•´ã€‚

è«‹è‡ªç¨±ã€Œå°ç¹ªã€ï¼Œä»¥æœ‹å‹èˆ¬çš„èªæ°£é™ªä¼´ä½¿ç”¨è€…å®Œæˆå‰µä½œã€‚
""".strip()

@app.route("/")
def index():
    return "LINE GPT Webhook is running!"

@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature")
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

# === å·¥å…·å‡½æ•¸ ===
def reset_story_memory(user_id):
    user_sessions[user_id] = {"messages": [], "story_mode": False}
    user_message_counts[user_id] = 0
    story_summaries[user_id] = ""
    story_titles[user_id] = ""
    story_image_prompts[user_id] = ""
    story_image_urls[user_id] = {}
    story_current_paragraph[user_id] = 0
    story_paragraphs[user_id] = []
    illustration_mode[user_id] = False
    practice_mode[user_id] = True
    print(f"âœ… å·²é‡ç½®ä½¿ç”¨è€… {user_id} çš„æ•…äº‹è¨˜æ†¶")

def generate_story_summary(messages):
    """æ ¹æ“šå°è©±æ­·å²ç”Ÿæˆæ•…äº‹ç¸½çµï¼Œåªå›å‚³äº”æ®µç´”æ•…äº‹å…§å®¹ï¼Œä¸è¦æœ‰é–‹å ´ç™½ã€åˆ†éš”ç·šã€æ¨™é¡Œç­‰é›œè¨Š"""
    try:
        summary_prompt = """
è«‹å°‡ä»¥ä¸‹å°è©±å…§å®¹æ•´ç†æˆäº”å€‹æ®µè½çš„æ•…äº‹æƒ…ç¯€ï¼Œæ¯æ®µç›´æ¥æ˜¯æ•…äº‹å…§å®¹ï¼Œä¸è¦åŠ å°æ¨™é¡Œã€é–‹å ´ç™½ã€åˆ†éš”ç·šã€æ¨™é¡Œã€æ„Ÿè¬èªæˆ–ä»»ä½•èªªæ˜æ–‡å­—ã€‚
æ¯æ®µç´„40å­—ï¼Œè«‹ç›¡é‡ä¿ç•™ç”¨æˆ¶æè¿°çš„ç´°ç¯€ï¼Œä¸è¦çœç•¥é‡è¦æƒ…ç¯€æˆ–è§’è‰²è¡Œå‹•ã€‚
è«‹ç¢ºä¿äº”æ®µæ•…äº‹æ¶µè“‹ç”¨æˆ¶æ‰€æœ‰æè¿°éçš„é‡è¦äº‹ä»¶èˆ‡ç´°ç¯€ã€‚
æ¯æ®µå‰é¢åŠ æ•¸å­—ï¼ˆ1. 2. 3. 4. 5.ï¼‰ã€‚
æ ¼å¼ç¯„ä¾‹ï¼š
1. å°æ˜åœ¨æ£®æ—è£¡ç™¼ç¾ä¸€éš»å—å‚·çš„å°é³¥ã€‚
2. ä»–æ±ºå®šå¸¶å°é³¥å›å®¶ç…§é¡§ã€‚
3. ç¶“éç´°å¿ƒç…§æ–™ï¼Œå°é³¥é€æ¼¸åº·å¾©ã€‚
4. å°é³¥å­¸æœƒäº†é£›è¡Œï¼Œä½†æ¨ä¸å¾—é›¢é–‹ã€‚
5. æœ€å¾Œå°é³¥é¸æ“‡ç•™ä¸‹ä¾†é™ªä¼´å°æ˜ã€‚

è«‹æŒ‰ç…§ä»¥ä¸Šæ ¼å¼æ•´ç†æ•…äº‹å…§å®¹ã€‚
"""
        messages_for_summary = [
            {"role": "system", "content": summary_prompt},
            {"role": "user", "content": "ä»¥ä¸‹æ˜¯æ•…äº‹å°è©±å…§å®¹ï¼š"},
            *messages
        ]
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages_for_summary,
            temperature=0.7,
        )
        return response.choices[0].message["content"]
    except Exception as e:
        print("âŒ ç”Ÿæˆæ•…äº‹ç¸½çµå¤±æ•—ï¼š", e)
        return None

def extract_story_paragraphs(summary):
    """å¾æ•…äº‹æ‘˜è¦ä¸­æå–5æ®µæ•…äº‹å…§å®¹ï¼Œéæ¿¾é–‹å ´ç™½èˆ‡éæ•…äº‹å…§å®¹"""
    paragraphs = [p.strip() for p in summary.split('\n') if p.strip()]
    filtered = [
        p for p in paragraphs
        if not re.match(r'^(å¥½çš„|ä»¥ä¸‹|è®“æˆ‘ä¾†|æ•´ç†ä¸€ä¸‹|æ•…äº‹å¦‚ä¸‹|Summary|Here is|Here are|è¬è¬|---|\*\*æ•…äº‹æ¨™é¡Œ)', p)
        and not re.match(r'^\*+$', p)
        and not re.match(r'^\*\*.*\*\*$', p)
    ]
    clean_paragraphs = [re.sub(r'^\d+\.\s*', '', p) for p in filtered]
    return clean_paragraphs[:5]

def optimize_image_prompt(story_content, user_prompt=""):
    """
    ç”¨ GPT-4 å°‡æ•…äº‹æ®µè½å’Œç”¨æˆ¶ç´°ç¯€æè¿°ï¼Œå„ªåŒ–æˆé©åˆ DALLÂ·E 3 çš„è‹±æ–‡ promptï¼Œä¸¦æ ¹æ“šç”¨æˆ¶æè¿°è‡ªè¨‚é¢¨æ ¼
    """
    try:
        style_map = {
            "æ°´å½©": "watercolor style, soft colors, gentle brush strokes",
            "æ²¹ç•«": "oil painting, thick brush strokes, canvas texture, oil paint style",
            "è‰²é‰›ç­†": "colored pencil drawing, hand-drawn, sketch style, colored pencils",
            "æ°´å¢¨": "Chinese ink wash painting, black and white, monochrome, ink brush, traditional Asian painting, ink style, no color",
            "å¯«å¯¦": "photorealistic, highly detailed, realistic style, lifelike, ultra-realistic",
            "ç¾ä»£": "modern art style, abstract, contemporary, modern design"
        }
        user_styles = []
        for zh, en in style_map.items():
            if zh in user_prompt:
                user_styles.append(en)
        style_english = ", ".join(user_styles)
        if style_english:
            style_english = f"{style_english}, {style_english}"
        detail_prompt = user_prompt
        base_instruction = (
            "Please rewrite the following story paragraph and user details into an English prompt suitable for a picture book illustration. "
            "No text, no words, no letters, no captions, no subtitles, no watermark. "
        )
        content = f"Story paragraph: {story_content}\nDetails: {detail_prompt}"
        if style_english:
            full_prompt = f"{style_english}. {content}"
        else:
            full_prompt = content
        messages = [
            {"role": "system", "content": base_instruction},
            {"role": "user", "content": full_prompt}
        ]
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
        )
        return response.choices[0].message["content"].strip()
    except Exception as e:
        print("âŒ å„ªåŒ–æ’åœ– prompt å¤±æ•—ï¼š", e)
        return None

def format_reply(text):
    return re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n', text)

def get_openai_response(user_id, user_message, encouragement_suffix=""):
    if user_id not in user_sessions or "messages" not in user_sessions[user_id]:
        user_sessions[user_id] = {"messages": [], "story_mode": False}
    if user_id not in user_message_counts:
        user_message_counts[user_id] = 0
    if user_id not in story_summaries:
        story_summaries[user_id] = ""
    if user_id not in story_current_paragraph:
        story_current_paragraph[user_id] = 0

    low_engagement_inputs = ["ä¸çŸ¥é“", "æ²’éˆæ„Ÿ", "å—¯", "ç®—äº†", "ä¸æƒ³èªª", "å…ˆè·³é", "è·³éé€™é¡Œ"]
    if any(phrase in user_message.strip().lower() for phrase in low_engagement_inputs):
        assistant_reply = random.choice([
            "æ²’é—œä¿‚ï¼Œæˆ‘å€‘å¯ä»¥æ…¢æ…¢æƒ³ ğŸ‘£",
            "å¦‚æœä¸æƒ³èªªï¼Œæˆ‘å€‘å¯ä»¥è·³éå–” ğŸ™‚",
            "ä¸ç”¨æ€¥ï½ä½ å·²ç¶“å¾ˆæ£’äº† ğŸ’ª"
        ])
        user_sessions[user_id]["messages"].append({"role": "user", "content": user_message})
        user_sessions[user_id]["messages"].append({"role": "assistant", "content": assistant_reply})
        return assistant_reply

    user_sessions[user_id]["messages"].append({"role": "user", "content": user_message})
    user_message_counts[user_id] += 1

    if user_message_counts[user_id] % 6 == 0:
        story_current_paragraph[user_id] = min(4, story_current_paragraph[user_id] + 1)

    summary_context = story_summaries.get(user_id, "")
    prompt_with_summary = base_system_prompt
    if summary_context:
        prompt_with_summary += f"\n\nã€æ•…äº‹æ‘˜è¦ã€‘\n{summary_context}\nè«‹æ ¹æ“šä»¥ä¸Šæ‘˜è¦ï¼Œå»¶çºŒå‰µä½œå°è©±å…§å®¹ã€‚"

    recent_history = user_sessions[user_id]["messages"][-30:]
    messages = [{"role": "system", "content": prompt_with_summary}] + recent_history

    try:
        print(f"ğŸ“¦ å‚³çµ¦ OpenAI çš„è¨Šæ¯ï¼š{json.dumps(messages, ensure_ascii=False)}")
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
        )
        raw_reply = response.choices[0].message["content"]
        assistant_reply = format_reply(raw_reply)

        if encouragement_suffix:
            assistant_reply += f"\n\n{encouragement_suffix}"

        user_sessions[user_id]["messages"].append({"role": "assistant", "content": assistant_reply})

        return assistant_reply

    except Exception as e:
        print("âŒ OpenAI å›æ‡‰éŒ¯èª¤ï¼š", e)
        traceback.print_exc()
        return None

def save_to_firebase(user_id, role, text):
    try:
        user_doc_ref = db.collection("users").document(user_id)
        user_doc_ref.collection("chat").add({
            "role": role,
            "text": text,
            "timestamp": firestore.SERVER_TIMESTAMP
        })
        print(f"âœ… Firebase å·²å„²å­˜è¨Šæ¯ï¼ˆ{role}ï¼‰")
    except Exception as e:
        print(f"âš ï¸ å„²å­˜ Firebase å¤±æ•—ï¼ˆ{role}ï¼‰ï¼š", e)

# === æ–°å¢ Leonardo.Ai åœ–ç‰‡ç”Ÿæˆå‡½å¼ï¼ˆé™¤éŒ¯ç‰ˆæœ¬ï¼‰ ===
def generate_leonardo_image(user_id, prompt, reference_image_url=None):
    """
    å‘¼å« Leonardo.Ai API ç”Ÿæˆåœ–ç‰‡ï¼Œä¸¦å¯ä½¿ç”¨åƒè€ƒåœ–ã€‚
    """
    try:
        if not LEONARDO_API_KEY:
            print("âŒ LEONARDO_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
            return None
        
        # âš ï¸ é™¤éŒ¯æ­¥é©Ÿï¼šç¢ºèª API Key è®€å–æ­£ç¢º
        print(f"DEBUG: è®€å–åˆ°çš„ API Key é•·åº¦ç‚º: {len(LEONARDO_API_KEY)}")

        # Leonardo.Ai çš„ç”Ÿæˆ API endpoint
        api_url = "https://cloud.leonardo.ai/api/v1/generations"
        headers = {
            "Authorization": f"Bearer {LEONARDO_API_KEY}",
            "Content-Type": "application/json"
        }

        # âš ï¸ é™¤éŒ¯æ­¥é©Ÿï¼šä½¿ç”¨ä¸€å€‹ç°¡å–®çš„ã€å›ºå®šçš„ prompt
        test_prompt = "A simple, beautiful watercolor illustration of a cat on a windowsill. No text, no words, no letters."

        payload = {
            "prompt": test_prompt, # æ›¿æ›ç‚ºé™¤éŒ¯ç”¨çš„å›ºå®š prompt
            "modelId": "6bef9f1b-29cb-40c8-b9d5-341ac2e02ad6", 
            "height": 768,
            "width": 768,
            "num_images": 1,
            "promptMagic": True,
            "promptMagicVersion": "v2",
            "negative_prompt": "text, words, captions, watermark, signature",
            "seed": -1,
            "num_inference_steps": 30
        }

        # å¦‚æœæœ‰åƒè€ƒåœ–ï¼Œå°±åŠ å…¥åƒè€ƒåœ–çš„åƒæ•¸
        if reference_image_url:
            payload["init_generation_image_url"] = reference_image_url
            payload["init_generation_strength"] = 0.6 
            print(f"ğŸ”— æ­£åœ¨ä½¿ç”¨åƒè€ƒåœ–ç‰‡: {reference_image_url}")

        print(f"ğŸ¨ å‘¼å« Leonardo.Ai API ç”¢ç”Ÿåœ–ç‰‡ä¸­ï¼Œprompt: {test_prompt}")
        
        response = requests.post(api_url, headers=headers, json=payload)
        
        # å¦‚æœå¤±æ•—ï¼Œå°‡éŒ¯èª¤è³‡è¨Šå°å‡ºä¾†
        if not response.ok:
            print(f"âŒ API è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            print(f"âŒ éŒ¯èª¤è¨Šæ¯: {response.text}")
        
        response.raise_for_status()

        # ... (å¾ŒçºŒç¨‹å¼ç¢¼ä¸è®Š)
        data = response.json()
        generation_id = data['sdGenerationJob']['generationId']
        print(f"âœ… ç”Ÿæˆä»»å‹™ ID: {generation_id}")

        image_url = wait_for_leonardo_image(generation_id)
        if image_url:
            print(f"âœ… åœ–ç‰‡ç”ŸæˆæˆåŠŸï¼ŒURL: {image_url}")
            return upload_to_gcs_from_url(image_url, user_id, prompt) # é€™è£¡ä¾ç„¶ç”¨åŸæœ¬çš„ prompt å„²å­˜
        else:
            print("âŒ åœ–ç‰‡ç”Ÿæˆé€¾æ™‚æˆ–å¤±æ•—")
            return None

    except Exception as e:
        print(f"âŒ Leonardo.Ai åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
        traceback.print_exc()
        return None

def wait_for_leonardo_image(generation_id, timeout=120):
    """
    è¼ªè©¢ Leonardo.Ai APIï¼Œç­‰å¾…åœ–ç‰‡ç”Ÿæˆå®Œæˆä¸¦è¿”å› URLã€‚
    """
    start_time = time.time()
    api_url = f"https://cloud.leonardo.ai/api/v1/generations/{generation_id}"
    headers = {
        "Authorization": f"Bearer {LEONARDO_API_KEY}"
    }

    while time.time() - start_time < timeout:
        time.sleep(5)
        try:
            response = requests.get(api_url, headers=headers)
            response.raise_for_status()
            data = response.json()

            if 'generations_v2' in data and data['generations_v2']:
                status = data['generations_v2'][0]['status']
                if status == 'COMPLETE':
                    image_url = data['generations_v2'][0]['generated_images'][0]['url']
                    return image_url
                elif status == 'FAILED':
                    print("âŒ Leonardo.Ai ç”Ÿæˆä»»å‹™å¤±æ•—")
                    return None
            else:
                print("âš ï¸ è¼ªè©¢ä¸­... ä»»å‹™å°šæœªé–‹å§‹æˆ–æ‰¾ä¸åˆ°è³‡æ–™")
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¼ªè©¢ Leonardo API å¤±æ•—: {e}")
            return None
    
    return None

def upload_to_gcs_from_url(image_url, user_id, prompt):
    """å¾ URL ä¸‹è¼‰åœ–ç‰‡ä¸¦ä¸Šå‚³åˆ° GCSï¼Œä¸¦ä¿å­˜è¨˜éŒ„åˆ° Firestore"""
    try:
        img_response = requests.get(image_url)
        img_response.raise_for_status()
        img_data = img_response.content
        filename = f"{user_id}_{uuid.uuid4().hex}.png"
        blob = bucket.blob(filename)
        blob.upload_from_string(img_data, content_type="image/png")
        gcs_url = f"https://storage.googleapis.com/{bucket_name}/{filename}"

        db.collection("users").document(user_id).collection("images").add({
            "url": gcs_url,
            "prompt": prompt,
            "timestamp": firestore.SERVER_TIMESTAMP
        })
        print(f"âœ… åœ–ç‰‡å·²ä¸Šå‚³è‡³ GCS ä¸¦å„²å­˜ï¼š{gcs_url}")
        return gcs_url
    except Exception as e:
        print(f"âŒ ä¸Šå‚³åœ–ç‰‡åˆ° GCS æˆ–å„²å­˜è¨˜éŒ„å¤±æ•—ï¼š{e}")
        traceback.print_exc()
        return None

# === ä¸»è¨Šæ¯è™•ç†å‡½å¼ ===
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = event.message.text
    reply_token = event.reply_token
    print(f"ğŸ“© æ”¶åˆ°ä½¿ç”¨è€… {user_id} çš„è¨Šæ¯ï¼š{user_text}")

    try:
        if re.search(r"(é–‹å§‹èªªæ•…äº‹|èªªæ•…äº‹|è¬›å€‹æ•…äº‹|èªªä¸€å€‹æ•…äº‹|è¬›ä¸€å€‹æ•…äº‹|ä¸€èµ·ä¾†è¬›æ•…äº‹å§|æˆ‘å€‘ä¾†è¬›æ•…äº‹å§)", user_text):
            reset_story_memory(user_id)
            user_sessions[user_id]["story_mode"] = True
            line_bot_api.reply_message(reply_token, TextSendMessage(
                text="å¤ªå¥½äº†ï¼Œæˆ‘å€‘é–‹å§‹è¬›æ•…äº‹å›‰ï¼ä¸»é¡Œæ˜¯ã€Œå¦‚æœæˆ‘æœ‰ä¸€å€‹è¶…èƒ½åŠ›ã€ï¼Œä½ æƒ³åˆ°çš„æ˜¯å“ªä¸€ç¨®è¶…èƒ½åŠ›å‘¢ï¼Ÿ"
            ))
            return

        # åœ¨æ•…äº‹æ¨¡å¼ä¸‹ï¼Œæª¢æŸ¥æ˜¯å¦éœ€è¦ç”¢ç”Ÿç¬¬ä¸€å¼µä¸»è§’åœ–
        if user_sessions.get(user_id, {}).get("story_mode", False) and 'reference_image_url' not in user_sessions[user_id]:
            # å‡è¨­åœ¨ç¬¬ 3 å‰‡è¨Šæ¯æ™‚ï¼Œä½¿ç”¨è€…å·²ç¶“æè¿°äº†ä¸»è§’ï¼Œæ­¤æ™‚å¯ä»¥ç”Ÿæˆç¬¬ä¸€å¼µä¸»è§’åœ–
            # ä½ å¯ä»¥æ ¹æ“šä½ çš„æµç¨‹èª¿æ•´è§¸ç™¼æ™‚æ©Ÿ
            if user_message_counts.get(user_id, 0) >= 3:
                # é‡æ–°ç”Ÿæˆæ•…äº‹æ‘˜è¦ä»¥å–å¾—å®Œæ•´ä¸»è§’æè¿°
                messages = user_sessions.get(user_id, {}).get("messages", [])
                summary = generate_story_summary(messages)
                
                if summary:
                    story_paragraphs[user_id] = extract_story_paragraphs(summary)
                    story_summaries[user_id] = summary
                    # ä½¿ç”¨ç¬¬ä¸€æ®µæ•…äº‹å…§å®¹ä½œç‚ºåˆå§‹ prompt
                    first_paragraph_prompt = story_paragraphs[user_id][0]
                    optimized_prompt = optimize_image_prompt(first_paragraph_prompt, "water color illustration style")
                    
                    if optimized_prompt:
                        image_url = generate_leonardo_image(user_id, optimized_prompt)
                        if image_url:
                            user_sessions[user_id]['reference_image_url'] = image_url
                            reply_messages = [
                                TextSendMessage(text="å¤ªæ£’äº†ï¼é€™æ˜¯æ•…äº‹ä¸»è§’çš„ç¬¬ä¸€å¼µåœ–ï¼Œä¹‹å¾Œçš„æ’åœ–éƒ½æœƒæ˜¯é€™å€‹é¢¨æ ¼å’Œä¸»è§’å–”ï¼š"),
                                ImageSendMessage(original_content_url=image_url, preview_image_url=image_url),
                                TextSendMessage(text="ä½ å–œæ­¡é€™å¼µåœ–å—ï¼Ÿæˆ‘å€‘å¯ä»¥ç¹¼çºŒèªªæ•…äº‹ï¼Œæˆ–æ˜¯ä½ ä¹Ÿå¯ä»¥éš¨æ™‚èªªã€å¹«æˆ‘ç•«ç¬¬Næ®µæ•…äº‹çš„åœ–ã€ä¾†ç”Ÿæˆä¸‹ä¸€å¼µæ’åœ–ã€‚")
                            ]
                            line_bot_api.reply_message(reply_token, reply_messages)
                            save_to_firebase(user_id, "user", user_text)
                            for msg in reply_messages:
                                if isinstance(msg, TextSendMessage):
                                    save_to_firebase(user_id, "assistant", msg.text)
                                elif isinstance(msg, ImageSendMessage):
                                    save_to_firebase(user_id, "assistant", f"[åœ–ç‰‡] {msg.original_content_url}")
                            return

        # === å°é¢ç”Ÿæˆåˆ†æ”¯ ===
        if re.search(r"å°é¢", user_text):
            cover_prompt = user_text.replace("å¹«æˆ‘ç•«å°é¢åœ–", "").replace("è«‹ç•«å°é¢", "").replace("ç•«å°é¢", "").strip()
            story_title = story_titles.get(user_id, "æˆ‘å€‘çš„æ•…äº‹")
            story_summary = story_summaries.get(user_id, "")
            optimized_prompt = optimize_image_prompt(story_summary, f"å°é¢ï¼š{cover_prompt}ï¼Œæ•…äº‹åç¨±ï¼š{story_title}")
            
            if not optimized_prompt:
                optimized_prompt = f"A beautiful, colorful storybook cover illustration. Title: {story_title}. {cover_prompt}. No text, no words, no letters."
            
            reference_image_url = user_sessions.get(user_id, {}).get('reference_image_url')
            image_url = generate_leonardo_image(user_id, optimized_prompt, reference_image_url) # å‚³å…¥åƒè€ƒåœ–
            
            if image_url:
                reply_messages = [
                    TextSendMessage(text="é€™æ˜¯ä½ æ•…äº‹çš„å°é¢ï¼š"),
                    ImageSendMessage(original_content_url=image_url, preview_image_url=image_url),
                    TextSendMessage(text="ä½ æ»¿æ„é€™å€‹å°é¢å—ï¼Ÿéœ€è¦èª¿æ•´å¯ä»¥å†æè¿°ä¸€æ¬¡å–”ï¼")
                ]
                line_bot_api.reply_message(reply_token, reply_messages)
                save_to_firebase(user_id, "user", user_text)
                for msg in reply_messages:
                    if isinstance(msg, TextSendMessage):
                        save_to_firebase(user_id, "assistant", msg.text)
                    elif isinstance(msg, ImageSendMessage):
                        save_to_firebase(user_id, "assistant", f"[åœ–ç‰‡] {msg.original_content_url}")
            else:
                line_bot_api.reply_message(reply_token, TextSendMessage(text="å°ç¹ªç•«ä¸å‡ºé€™å€‹å°é¢ï¼Œè©¦è©¦å…¶ä»–æè¿°çœ‹çœ‹ ğŸ–ï¸"))
            return
        
        # === æ’åœ–ç”Ÿæˆåˆ†æ”¯ ===
        if re.search(r"(å¹«æˆ‘ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„åœ–|è«‹ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„æ’åœ–|ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„åœ–)", user_text):
            match = re.search(r"[ä¸€äºŒä¸‰å››äº”12345]", user_text)
            paragraph_map = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}
            paragraph_num = paragraph_map.get(match.group(0) if match else None, 1) - 1

            messages = user_sessions.get(user_id, {}).get("messages", [])
            summary = generate_story_summary(messages)
            if summary:
                story_paragraphs[user_id] = extract_story_paragraphs(summary)
                story_summaries[user_id] = summary
            
            if not story_paragraphs.get(user_id) or not (0 <= paragraph_num < len(story_paragraphs[user_id])):
                line_bot_api.reply_message(reply_token, TextSendMessage(text="å°ç¹ªé‚„æ²’æœ‰æ•´ç†å¥½é€™æ®µæ•…äº‹ï¼Œè«‹å†å¤šèªªä¸€é»ç´°ç¯€å§ï¼"))
                return
            
            story_content = story_paragraphs[user_id][paragraph_num]
            user_extra_desc = re.sub(r"(å¹«æˆ‘ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„åœ–|è«‹ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„æ’åœ–|ç•«ç¬¬[ä¸€äºŒä¸‰å››äº”12345]æ®µæ•…äº‹çš„åœ–)[ï¼Œ,ã€‚.!ï¼]*", "", user_text).strip()
            
            optimized_prompt = optimize_image_prompt(story_content, user_extra_desc)
            if not optimized_prompt:
                optimized_prompt = f"A colorful, soft, watercolor-style picture book illustration for children, no text, no words, no letters. Story: {story_content} {user_extra_desc}"
            
            reference_image_url = user_sessions.get(user_id, {}).get('reference_image_url')
            image_url = generate_leonardo_image(user_id, optimized_prompt, reference_image_url) # å‚³å…¥åƒè€ƒåœ–
            
            if image_url:
                reply_messages = [
                    TextSendMessage(text=f"é€™æ˜¯ç¬¬ {paragraph_num + 1} æ®µæ•…äº‹çš„æ’åœ–ï¼š"),
                    ImageSendMessage(original_content_url=image_url, preview_image_url=image_url)
                ]
                line_bot_api.reply_message(reply_token, reply_messages)
                save_to_firebase(user_id, "user", user_text)
                for msg in reply_messages:
                    if isinstance(msg, TextSendMessage):
                        save_to_firebase(user_id, "assistant", msg.text)
                    elif isinstance(msg, ImageSendMessage):
                        save_to_firebase(user_id, "assistant", f"[åœ–ç‰‡] {msg.original_content_url}")
            else:
                line_bot_api.reply_message(reply_token, TextSendMessage(text="å°ç¹ªç•«ä¸å‡ºé€™å¼µåœ–ï¼Œè©¦è©¦å…¶ä»–æè¿°çœ‹çœ‹ ğŸ–ï¸"))
            return
        
        # === æ•…äº‹æ¨™é¡Œç”Ÿæˆåˆ†æ”¯ ===
        if re.search(r"(å–æ•…äº‹æ¨™é¡Œ|å¹«æˆ‘å–æ•…äº‹æ¨™é¡Œ|å–æ¨™é¡Œ|å¹«æˆ‘æƒ³æ¨™é¡Œ)", user_text):
            story_summary = story_summaries.get(user_id, "")
            if not story_summary:
                line_bot_api.reply_message(reply_token, TextSendMessage(text="ç›®å‰é‚„æ²’æœ‰æ•…äº‹å¤§ç¶±ï¼Œè«‹å…ˆå®Œæˆæ•…äº‹å…§å®¹å–”ï¼"))
                return
            
            title_prompt = f"è«‹æ ¹æ“šä»¥ä¸‹æ•…äº‹å¤§ç¶±ï¼Œç”¢ç”Ÿä¸‰å€‹é©åˆçš„æ•…äº‹æ›¸æ¨™é¡Œï¼Œæ¯å€‹ä¸è¶…é8å­—ï¼Œä¸¦ç”¨1. 2. 3. ç·¨è™Ÿï¼š\n{story_summary}"
            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ“…é•·ç‚ºæ•…äº‹å–åçš„AIï¼Œè«‹æ ¹æ“šæ•…äº‹å¤§ç¶±ç”¢ç”Ÿä¸‰å€‹ç°¡æ½”æœ‰å‰µæ„çš„æ•…äº‹æ›¸æ¨™é¡Œï¼Œæ¯å€‹ä¸è¶…é8å­—ã€‚"},
                    {"role": "user", "content": title_prompt}
                ],
                temperature=0.7,
            )
            titles = response.choices[0].message["content"].strip()
            line_bot_api.reply_message(reply_token, TextSendMessage(
                text=f"é€™è£¡æœ‰ä¸‰å€‹æ•…äº‹æ¨™é¡Œé¸é …ï¼š\n{titles}\n\nè«‹å›è¦†ä½ æœ€å–œæ­¡çš„ç·¨è™Ÿæˆ–ç›´æ¥è¼¸å…¥æ¨™é¡Œï¼"
            ))
            save_to_firebase(user_id, "user", user_text)
            save_to_firebase(user_id, "assistant", f"æ•…äº‹æ¨™é¡Œé¸é …ï¼š\n{titles}")
            return
        
        # === ä¸€èˆ¬å°è©±åˆ†æ”¯ ===
        encouragement_suffix = ""
        if user_sessions.get(user_id, {}).get("story_mode", False):
            encouragement_suffix = random.choice([
                "ä½ çœŸçš„å¾ˆæœ‰å‰µæ„ï¼æˆ‘å–œæ­¡é€™å€‹è¨­è¨ˆï¼ğŸŒŸ",
                "éå¸¸å¥½ï¼Œæˆ‘è¦ºå¾—é€™å€‹æƒ³æ³•å¾ˆä¸éŒ¯ï¼ğŸ‘",
                "ç¹¼çºŒåŠ æ²¹ï¼Œä½ åšå¾—å¾ˆæ£’ï¼ğŸ’ª",
                "ä½ çœŸæ˜¯æ•…äº‹å¤§å¸«ï¼ğŸ˜Š"
            ])
        
        assistant_reply = get_openai_response(user_id, user_text, encouragement_suffix)

        if not assistant_reply:
            line_bot_api.reply_message(reply_token, TextSendMessage(text="å°ç¹ªæš«æ™‚å¡ä½äº†ï¼Œè«‹ç¨å¾Œå†è©¦å–”"))
            return

        line_bot_api.reply_message(reply_token, TextSendMessage(text=assistant_reply))
        save_to_firebase(user_id, "user", user_text)
        save_to_firebase(user_id, "assistant", assistant_reply)

    except Exception as e:
        print("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
        traceback.print_exc()
        line_bot_api.reply_message(reply_token, TextSendMessage(text="å°ç¹ªå‡ºäº†ä¸€é»å°ç‹€æ³ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™‡"))

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
